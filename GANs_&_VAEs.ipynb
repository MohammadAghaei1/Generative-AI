{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGtkGdqjBX7wJV+EU2ab+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadAghaei1/Generative-AI/blob/main/GANs_%26_VAEs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries**"
      ],
      "metadata": {
        "id": "lAkWCgKsik_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, BatchNormalization, LeakyReLU, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "VsyNP1FigKBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading dataset**"
      ],
      "metadata": {
        "id": "qBfGEoLtlSJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape to (28, 28, 1)\n",
        "X_train = X_train.astype(np.float32) / 255.0\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "# Check the shape of the data\n",
        "print(X_train.shape)\n"
      ],
      "metadata": {
        "id": "EbQiGqhaQno5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking activation of GPU**"
      ],
      "metadata": {
        "id": "ThxNw0KvixwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "9mTrDGqAihSn",
        "outputId": "052a18c8-216d-4913-851a-8b7d921f6ea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Generator**"
      ],
      "metadata": {
        "id": "lkPU41yTQ0U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    generator = Sequential()\n",
        "\n",
        "    # Start with a dense layer that outputs a 7x7x128 tensor\n",
        "    generator.add(Dense(128 * 7 * 7, input_dim=100))\n",
        "    generator.add(LeakyReLU(alpha=0.2))\n",
        "    generator.add(BatchNormalization(momentum=0.8))\n",
        "    generator.add(Reshape((7, 7, 128)))  # Reshape to (7, 7, 128)\n",
        "\n",
        "    # Upsample to 14x14\n",
        "    generator.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "    generator.add(LeakyReLU(alpha=0.2))\n",
        "    generator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # Upsample to 28x28\n",
        "    generator.add(Conv2DTranspose(64, kernel_size=3, strides=2, padding='same'))\n",
        "    generator.add(LeakyReLU(alpha=0.2))\n",
        "    generator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # Final layer to get the output to 28x28x1\n",
        "    generator.add(Conv2DTranspose(1, kernel_size=3, strides=1, padding='same', activation='tanh'))\n",
        "\n",
        "    noise = Input(shape=(100,))\n",
        "    img = generator(noise)\n",
        "\n",
        "    return generator(noise, img)\n"
      ],
      "metadata": {
        "id": "wXpKOjqmQ-KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()"
      ],
      "metadata": {
        "id": "qtHtS01vRzjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Discriminator**"
      ],
      "metadata": {
        "id": "X3MVj-UcSf5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\n",
        "  discriminator = Sequential()\n",
        "  discriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(28,28,1), padding=\"same\"))\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "  discriminator.add(Dropout(0.25))\n",
        "\n",
        "  discriminator.add(Conv2D(64, kernel_size=3, strides=2,padding=\"same\"))\n",
        "  discriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "  discriminator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "  discriminator.add(Dropout(0.25))\n",
        "\n",
        "  discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  discriminator.add(BatchNormalization(momentum=0.8))\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "  discriminator.add(Dropout(0.25))\n",
        "\n",
        "  discriminator.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "  discriminator.add(BatchNormalization(momentum=0.8))\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "  discriminator.add(Dropout(0.25))\n",
        "\n",
        "  discriminator.add(Flatten())\n",
        "  discriminator.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  img = Input(shape=(28,28,1))\n",
        "  probability = discriminator(img)\n",
        "\n",
        "  return discriminator(inputs=img, outputs=probability)"
      ],
      "metadata": {
        "id": "BJ1Yp9o8Sj6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "XbuIoc3QTWnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Gan**"
      ],
      "metadata": {
        "id": "wJYOGgBJUoZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "# build discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# For the combined model we will only train the generator\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build the generator\n",
        "generator = build_generator()\n",
        "\n",
        "z = Input(shape=(100,))\n",
        "img = generator(z)\n",
        "\n",
        "# The discriminator takes generated images as input and determines validity\n",
        "valid = discriminator(img)\n",
        "\n",
        "# The combined model  (stacked generator and discriminator)\n",
        "# Trains the generator to fool the discriminator\n",
        "combined = Model(inputs=z, outputs=valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "id": "3xAslK6ZUr-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined.summary()"
      ],
      "metadata": {
        "id": "WMIdxr40W9Zl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}