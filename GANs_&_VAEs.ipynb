{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2DC+0OfaOz+cFsb1V8dSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadAghaei1/Generative-AI/blob/main/GANs_%26_VAEs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries**"
      ],
      "metadata": {
        "id": "lAkWCgKsik_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "VsyNP1FigKBY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading dataset**"
      ],
      "metadata": {
        "id": "qBfGEoLtlSJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD AND PREPROCESS DATA\n",
        "print(\"Loading MNIST data...\")\n",
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Reshape from (60000, 28, 28) → (60000, 28, 28, 1)\n",
        "# Add channel dimension for Conv2D (1 = grayscale)\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# Normalize pixel values from [0, 255] → [-1, 1]\n",
        "train_images = (train_images - 127.5) / 127.5\n",
        "\n",
        "# Dataset parameters\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "#  - shuffle it\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Check the shape of the data\n",
        "print(train_dataset.shape)"
      ],
      "metadata": {
        "id": "tAzCA4FCUt2r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking activation of GPU**"
      ],
      "metadata": {
        "id": "ThxNw0KvixwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "9mTrDGqAihSn",
        "outputId": "9c725071-51b1-4f17-d20f-7bc5d1e961b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Generator**"
      ],
      "metadata": {
        "id": "lkPU41yTQ0U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model(noise_dim):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Input: Random Noise\n",
        "    # # Start with a dense layer that outputs a 7x7x128 tensor\n",
        "    model.add(layers.Dense(7*7*128, use_bias=False, input_shape=(noise_dim,)))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Reshape((7, 7, 128)))\n",
        "\n",
        "    # Upsample from 7x7 to 14x14\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # Upsample from 14x14 to 28x28\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))  #\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # Refine 28x28 (Stride = 1)\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "wXpKOjqmQ-KZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "482eaa89-c816-446b-deb7-0aa63fe2a2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def build_generator():\\n\\n    model = Sequential()\\n\\n\\n    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=100))\\n    model.add(Reshape((7, 7, 128)))\\n\\n    model.add(UpSampling2D())\\n    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\\n    model.add(BatchNormalization(momentum=0.8))\\n    model.add(Activation(\"relu\"))\\n\\n    model.add(UpSampling2D())\\n    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\\n    model.add(BatchNormalization(momentum=0.8))\\n    model.add(Activation(\"relu\"))\\n\\n    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\\n    model.add(Activation(\"tanh\"))\\n\\n    model.summary()\\n\\n    noise = Input(shape=(100,))\\n    img = model(noise)\\n\\n    return Model(noise, img)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "generator = make_generator_model(NOISE_DIM)"
      ],
      "metadata": {
        "id": "dNzZ5l-OyJeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Discriminator**"
      ],
      "metadata": {
        "id": "X3MVj-UcSf5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # --- Block 1: 32 Filters (Input) ---\n",
        "    # Matches Code A: Conv2D(32) -> LeakyReLU -> Dropout\n",
        "    model.add(layers.Conv2D(32, kernel_size=3, strides=2, padding='same', input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    # --- Block 2: 64 Filters ---\n",
        "    # Matches Code A: Conv2D(64) -> BN -> LeakyReLU -> Dropout\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
        "    # Note: I used padding='same' instead of manual ZeroPadding2D to prevent shape errors\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    # --- Block 3: 128 Filters ---\n",
        "    # Matches Code A: Conv2D(128) -> BN -> LeakyReLU -> Dropout\n",
        "    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    # --- Block 4: 256 Filters ---\n",
        "    # Matches Code A: Conv2D(256) -> BN -> LeakyReLU -> Dropout\n",
        "    # Note: Strides=1 here (just like Code A) to refine features without shrinking size\n",
        "    model.add(layers.Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    # --- Output ---\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "BJ1Yp9o8Sj6y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "906751a8-519f-4c14-c9ed-56673ce6dafb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def build_discriminator():\\n\\n    model = Sequential()\\n\\n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(28,28,1), padding=\"same\"))\\n    model.add(LeakyReLU(alpha=0.2))\\n    model.add(Dropout(0.25))\\n\\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\\n    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\\n    model.add(BatchNormalization(momentum=0.8))\\n    model.add(LeakyReLU(alpha=0.2))\\n    model.add(Dropout(0.25))\\n\\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\\n    model.add(BatchNormalization(momentum=0.8))\\n    model.add(LeakyReLU(alpha=0.2))\\n    model.add(Dropout(0.25))\\n\\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\\n    model.add(BatchNormalization(momentum=0.8))\\n    model.add(LeakyReLU(alpha=0.2))\\n    model.add(Dropout(0.25))\\n\\n    model.add(Flatten())\\n    model.add(Dense(1, activation=\\'sigmoid\\'))\\n\\n    model.summary()\\n\\n    img = Input(shape=(28,28,1))\\n    validity = model(img)\\n    return Model(img, validity)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator_model()"
      ],
      "metadata": {
        "id": "M5JIAsu47igj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss functions and optimizers**"
      ],
      "metadata": {
        "id": "h3LQxkmxAPKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary cross-entropy loss for real/fake classification\n",
        "# from_logits=False because discriminator uses sigmoid\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    \"\"\"\n",
        "    real_output: D(real images)  -> should be close to 1\n",
        "    fake_output: D(fake images)  -> should be close to 0\n",
        "    \"\"\"\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)   # label 1 for real\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)  # label 0 for fake\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    \"\"\"\n",
        "    fake_output: D(fake images)\n",
        "    Generator wants D(fake) ≈ 1 (fool the discriminator)\n",
        "    \"\"\"\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)  # want label 1 for fake\n"
      ],
      "metadata": {
        "id": "N_LhdJvTAOoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)"
      ],
      "metadata": {
        "id": "584h_tSXAtJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making DCGAN**"
      ],
      "metadata": {
        "id": "wJYOGgBJUoZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    \"\"\"\n",
        "    Performs one training step on a batch of real images:\n",
        "      - sample noise\n",
        "      - generate fake images\n",
        "      - compute discriminator and generator losses\n",
        "      - update both networks\n",
        "      - compute discriminator accuracy on real and fake\n",
        "    \"\"\"\n",
        "    # Sample random noise for the generator: (batch_size, NOISE_DIM)\n",
        "    # Here batch_size is fixed to 128, matching BATCH_SIZE\n",
        "    noise = tf.random.normal([128, NOISE_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generate fake images from noise\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        # Discriminator output for real and fake images\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        # Compute losses\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Apply gradients (update weights)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    # ----- Discriminator accuracies -----\n",
        "    # Real images: correct if prediction > 0.5 (classified as real)\n",
        "    real_pred = tf.cast(real_output > 0.5, tf.float32)\n",
        "    real_acc = tf.reduce_mean(real_pred)  # fraction of real images correctly classified\n",
        "\n",
        "    # Fake images: correct if prediction <= 0.5 (classified as fake)\n",
        "    fake_pred_real = tf.cast(fake_output > 0.5, tf.float32)  # 1 if predicted real (wrong)\n",
        "    fake_acc = tf.reduce_mean(1.0 - fake_pred_real)          # 1 - wrong = correct\n",
        "\n",
        "    return gen_loss, disc_loss, real_acc, fake_acc\n"
      ],
      "metadata": {
        "id": "v0Q85J-IGXeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function for saving and plotting images**"
      ],
      "metadata": {
        "id": "3y1cfwVEGbGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    \"\"\"\n",
        "    Generate images from a fixed noise vector (test_input)\n",
        "    and plot them in a 4x4 grid.\n",
        "    \"\"\"\n",
        "    # Disable training behavior (e.g., batchnorm updates)\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "\n",
        "        # Convert from [-1, 1] back to [0, 1] for display\n",
        "        img_to_plot = (predictions[i, :, :, 0] + 1) / 2.0\n",
        "\n",
        "        plt.imshow(img_to_plot, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f'Epoch {epoch}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9tCNXj8oGbfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Traning**"
      ],
      "metadata": {
        "id": "PfQFWkzuh5Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "    print(\"Starting training with Tanh [-1, 1]...\")\n",
        "\n",
        "    # Batch the dataset here (we kept it unbatched before)\n",
        "    BATCH_SIZE = 128\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        g_loss_metric = 0.0\n",
        "        d_loss_metric = 0.0\n",
        "        real_acc_metric = 0.0\n",
        "        fake_acc_metric = 0.0\n",
        "        steps = 0\n",
        "\n",
        "        # Iterate over all batches in the dataset\n",
        "        for image_batch in dataset:\n",
        "            g_loss, d_loss, real_acc, fake_acc = train_step(image_batch)\n",
        "            g_loss_metric += g_loss\n",
        "            d_loss_metric += d_loss\n",
        "            real_acc_metric += real_acc\n",
        "            fake_acc_metric += fake_acc\n",
        "            steps += 1\n",
        "\n",
        "        # Average over all batches (epoch metrics)\n",
        "        avg_g_loss = g_loss_metric / steps\n",
        "        avg_d_loss = d_loss_metric / steps\n",
        "        avg_real_acc = real_acc_metric / steps\n",
        "        avg_fake_acc = fake_acc_metric / steps\n",
        "\n",
        "        # Print losses + discriminator accuracies (in %)\n",
        "        print(\n",
        "            f'Epoch {epoch + 1}, '\n",
        "            f'Gen Loss: {avg_g_loss:.4f}, '\n",
        "            f'Disc Loss: {avg_d_loss:.4f}, '\n",
        "            f'D(real)%: {avg_real_acc * 100:.1f}, '\n",
        "            f'D(fake)%: {avg_fake_acc * 100:.1f}'\n",
        "        )\n",
        "\n",
        "        # Visualize 16 generated images from a fixed noise vector\n",
        "        generate_and_save_images(generator, epoch + 1, seed)\n"
      ],
      "metadata": {
        "id": "XYJF5Ipwh4kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running DCGAN**"
      ],
      "metadata": {
        "id": "lf28TlWlHABB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed noise vector used for monitoring generator progress\n",
        "seed = tf.random.normal([16, NOISE_DIM])\n",
        "train(train_dataset, epochs=50)"
      ],
      "metadata": {
        "id": "pfOsBxXSHDIT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}