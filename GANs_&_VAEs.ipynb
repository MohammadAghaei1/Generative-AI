{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmBDBjHMzR6YU6TPYHLCeg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadAghaei1/Generative-AI/blob/main/GANs_%26_VAEs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries**"
      ],
      "metadata": {
        "id": "lAkWCgKsik_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, BatchNormalization, LeakyReLU, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "VsyNP1FigKBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading dataset**"
      ],
      "metadata": {
        "id": "qBfGEoLtlSJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape to (28, 28, 1)\n",
        "X_train = X_train.astype(np.float32) / 255.0\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "# Check the shape of the data\n",
        "print(X_train.shape)\n"
      ],
      "metadata": {
        "id": "EbQiGqhaQno5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking activation of GPU**"
      ],
      "metadata": {
        "id": "ThxNw0KvixwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "9mTrDGqAihSn",
        "outputId": "052a18c8-216d-4913-851a-8b7d921f6ea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Generator**"
      ],
      "metadata": {
        "id": "lkPU41yTQ0U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Start with a dense layer that outputs a 7x7x128 tensor\n",
        "    model.add(Dense(128 * 7 * 7, input_dim=100))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Reshape((7, 7, 128)))  # Reshape to (7, 7, 128)\n",
        "\n",
        "    # Upsample to 14x14\n",
        "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # Upsample to 28x28\n",
        "    model.add(Conv2DTranspose(64, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # Final layer to get the output to 28x28x1\n",
        "    model.add(Conv2DTranspose(1, kernel_size=3, strides=1, padding='same', activation='tanh'))\n",
        "\n",
        "    noise = Input(shape=(100,))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)\n"
      ],
      "metadata": {
        "id": "wXpKOjqmQ-KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "qtHtS01vRzjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Discriminator**"
      ],
      "metadata": {
        "id": "X3MVj-UcSf5g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJ1Yp9o8Sj6y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}